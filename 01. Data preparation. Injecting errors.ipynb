{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e804a0-ae02-4c26-a180-58180cf1002b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Preliminary steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55d38cd-d1be-4915-b0e0-5af6f5cea7ba",
   "metadata": {},
   "source": [
    "## Get thelibraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b372b-1578-4213-9f0a-a27ae2549772",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.27.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ab4f68-999b-45fb-9db5-bc1e250ef8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fca975-8c39-4579-b23d-4a22a741153e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Get the tokeniser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bd34ce-d348-4e1c-9bb3-e056a8478dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained(\"pstroe/roberta-base-latin-cased\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8e94f5-0bb7-450e-9249-1d625c39cd4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Prepare the training data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69ea55d-292d-4d7e-bc94-6e8e64931e1e",
   "metadata": {},
   "source": [
    "## Import the list of errors typical for your transcription model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fe47bb-9096-4a49-9669-4e1c0c2e6685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error = pd.read_csv(\"data/errors_final.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169076c7-3b39-4543-af99-35dcb6c92e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error.iloc[625]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3f92d7-ade9-4535-a125-c42ca93881cd",
   "metadata": {},
   "source": [
    "## Aggregate it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6785f254-4fa3-4ed0-b532-f5875b5b41ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error[\"is_na_correct\"] = df_error[\"correct\"].isnull()\n",
    "df_error[\"is_na_error\"] = df_error[\"error\"].isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bac85a-d2fe-4efc-aeca-974b6c34b1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_regexp(x):\n",
    "    if x[\"context\"] == \"––\":\n",
    "        return x[\"correct\"]\n",
    "    if x[\"is_na_error\"]:\n",
    "        st = x[\"context\"].index(\"[\")\n",
    "        en = x[\"context\"].index(\"]\", st)\n",
    "        return str(x[\"context\"][:st]) + str(x[\"correct\"]) + str(x[\"context\"][en + 1 :])\n",
    "    if x[\"is_na_correct\"]:\n",
    "        st = x[\"context\"].index(\"_\")\n",
    "        return x[\"context\"][:st] + x[\"context\"][st + 1 :]\n",
    "\n",
    "\n",
    "def get_error_with_contecst(x):\n",
    "    if x[\"context\"] == \"––\":\n",
    "        return x[\"error\"]\n",
    "    if x[\"is_na_error\"]:\n",
    "        st = x[\"context\"].index(\"[\")\n",
    "        en = x[\"context\"].index(\"]\", st)\n",
    "        return str(x[\"context\"][:st]) + str(x[\"context\"][en + 1 :])\n",
    "    if x[\"is_na_correct\"]:\n",
    "        st = x[\"context\"].index(\"_\")\n",
    "        return x[\"context\"][:st] + x[\"error\"] + x[\"context\"][st + 1 :]\n",
    "\n",
    "\n",
    "def get_count_error_symbol(x):\n",
    "    if x[\"is_na_correct\"]:\n",
    "        return len(x[\"error\"])\n",
    "    return len(x[\"correct\"])\n",
    "\n",
    "\n",
    "df_error[\"regexp\"] = df_error.apply(get_regexp, axis=1)\n",
    "df_error[\"context_with_error\"] = df_error.apply(get_error_with_contecst, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9fafc5-14dd-4fa0-8c6a-56c39396f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error[\"regexp\"] = df_error[\"regexp\"].apply(lambda x: \"\\?\" if x == \"?\" else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbad2a1-b107-4535-8167-8906fb576ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error[\"count_symbol\"] = df_error.apply(\n",
    "    lambda x: x[\"count\"]\n",
    "    * (len(x[\"error\"]) if x[\"is_na_correct\"] else len(x[\"correct\"])),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da95ad23-f9ca-44cc-bf69-9df1c125cc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c75d7-1920-49a4-98c5-645c4c82799d",
   "metadata": {},
   "source": [
    "## Obtain information about the errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb059c2-a71c-4919-b6bc-94d108f27388",
   "metadata": {},
   "source": [
    "### Stats calculation to evaluate the error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6edca65-e0e2-4d34-a8c9-3e313496dff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(df[\"target_text\"].tolist())\n",
    "\n",
    "res_count_in = {}\n",
    "for ex in tqdm(df_error[\"regexp\"].unique(), total=len(df_error[\"regexp\"].unique())):\n",
    "    count_in = len(re.findall(repr(ex).strip(\"'\"), text))\n",
    "    res_count_in[ex] = count_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c342bd-9c40-4e57-b863-ee7b1091d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_count_error_in = {}\n",
    "for ex in tqdm(df_error[\"regexp\"].unique(), total=len(df_error[\"regexp\"].unique())):\n",
    "    count_in = df_error[df_error[\"regexp\"] == ex][\"count\"].sum()\n",
    "    res_count_error_in[ex] = count_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dadf824-967f-407e-826f-9697309b0648",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error[df_error[\"regexp\"] == \" ceato\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec0734-5cfc-4acd-b938-31326b04d18c",
   "metadata": {},
   "source": [
    "### Calculate the error_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155e777b-61ef-4273-91da-a139e6fe6510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error[\"error_rate\"] = df_error.apply(\n",
    "    lambda x: (\n",
    "        min(res_count_error_in[x[\"regexp\"]] / res_count_in[x[\"regexp\"]], 0.3)\n",
    "        if res_count_in[x[\"regexp\"]] != 0\n",
    "        else 0.3\n",
    "    ),\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e61bff-6791-478d-aa7e-baf01de551bc",
   "metadata": {},
   "source": [
    "### Compiling the regexps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac446b9f-bd90-47fc-9098-0b9555224b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error[\"comp_regexp\"] = df_error[\"regexp\"].apply(\n",
    "    lambda x: re.compile(repr(x).strip(\"'\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b147c2-6629-4a25-b125-ac23dc18ca65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db37fce-33ea-46b9-a41d-f879e20df506",
   "metadata": {},
   "source": [
    "### Get an error bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fbcbff-147d-4a8d-a80e-c9b21e1453ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_bank = []\n",
    "uniq_cont = df_error[\"regexp\"].unique()\n",
    "for ex in tqdm(uniq_cont, total=len(uniq_cont)):\n",
    "    el = df_error[df_error[\"regexp\"] == ex]\n",
    "    prob = np.array(el[\"count\"].tolist()) / el[\"count\"].sum() * el.iloc[0][\"error_rate\"]\n",
    "    error_bank.append(\n",
    "        [ex, el[\"comp_regexp\"].iloc[0], el[\"context_with_error\"].tolist(), prob]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981d9a70-1c1f-43c4-8668-327ae62fad4f",
   "metadata": {},
   "source": [
    "## Get all the separate xmls and parse them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d18cf3-0146-4df1-9544-aad5a511b9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "pathlist = Path(\"data/PL\").glob(\"*.xml\")\n",
    "pathlist = list(pathlist)\n",
    "print(len(pathlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f379340a-d0d6-4e0f-9616-3235fd6cf8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "res_new_str = (\n",
    "    []\n",
    ")  # a list created out of the cycle to aggregate the results for all files\n",
    "\n",
    "path_t = tqdm(pathlist, total=len(pathlist))\n",
    "\n",
    "for path in tqdm(path_t):  # progress bar for the fields\n",
    "    with open(path, \"r\") as fp:\n",
    "        soup = BeautifulSoup(fp, \"xml\")\n",
    "\n",
    "    body = soup.find(\"body\")\n",
    "    if body is None:\n",
    "        print(f\"There is no <body> in file: {path}\")\n",
    "        continue\n",
    "\n",
    "    paragraphs = body.find_all(\"p\")  # get all the paragraphs\n",
    "    if not paragraphs:\n",
    "        print(f\"There is no <p> in file: {path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"I found {len(paragraphs)} paragraphs in file: {path}\")\n",
    "\n",
    "    for tag in paragraphs:\n",
    "        text = tag.text.strip()\n",
    "        original_text = text  # save the text for comparaison\n",
    "        text = text.replace(\"\\n\", \" \")\n",
    "        text = re.sub(r\"[^a-zA-Z0-9 .:!]\", \"\", text)\n",
    "        text = re.sub(r\"  +\", \" \", text)\n",
    "\n",
    "        if not text:  # is there any text left ?\n",
    "            print(f\"Text filtered in: {path}\")\n",
    "            print(f\"Original text: {original_text}\")\n",
    "            continue\n",
    "\n",
    "        l_t = len(text)\n",
    "        if l_t > 500:\n",
    "            i = 2\n",
    "            while l_t // i > 500:\n",
    "                i += 1\n",
    "            len_msg = l_t // i\n",
    "            prev_pos = 0\n",
    "            sep = \".\"\n",
    "            while l_t - prev_pos > 500 and (prev_pos >= 0) and (l_t > prev_pos):\n",
    "                cur_pos = text.find(sep, prev_pos + len_msg)\n",
    "                if cur_pos == -1 or cur_pos - prev_pos > 700:\n",
    "                    sep = \" \"\n",
    "                    cur_pos = text.find(sep, prev_pos + len_msg)\n",
    "                    sep = \".\"\n",
    "                    if cur_pos == -1:\n",
    "                        prev_pos = l_t\n",
    "                        print(\"Text slicing error:\", path)\n",
    "                        continue\n",
    "                res_new_str.append(text[prev_pos : cur_pos + 1])\n",
    "                prev_pos = cur_pos + 1\n",
    "            res_new_str.append(text[prev_pos:])\n",
    "        else:\n",
    "            res_new_str.append(text)\n",
    "\n",
    "print(\"Number of lines after processing all files:\", len(res_new_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1946dc-baa1-4e60-b82e-4b3c92e2cb75",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of lines after processing the whole corpus:\", len(res_new_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579456bd-7702-4a4f-a379-78a22f63b417",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_pos, len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bfaa3f-f079-4c39-a89b-e0ec9e39dd64",
   "metadata": {},
   "source": [
    "## Plot texts length distribution over the corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fa6382-707f-46d8-aa07-112e73ae1a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dd = [len(s) for s in res_new_str]\n",
    "_ = plt.hist(dd, bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b51692-daef-4418-b3c8-45ac734c7a1c",
   "metadata": {},
   "source": [
    "## Inject the errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308b974f-a8dd-4227-b72e-fe0913824ff5",
   "metadata": {},
   "source": [
    "###  Function that replaces some pieces of text according to the error probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0157e-a079-497b-80b7-3f941e12126c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_with_error(x):\n",
    "\n",
    "    name_proc = current_process().name\n",
    "\n",
    "    correct_text, error_bank = x\n",
    "    incorrect_text = []\n",
    "    for cor_txt in correct_text:\n",
    "        err_txt = cor_txt  # create a copy of each correct line\n",
    "        l_er = list(\n",
    "            range(len(error_bank))\n",
    "        )  # randomly shuffle the list of indexes of all elements from error_bank\n",
    "        random.shuffle(l_er)\n",
    "        for i in l_er:\n",
    "            el = error_bank[i]\n",
    "            coef = 3.0\n",
    "            pr = list(el[3] * coef) + [1 - ((el[3] * coef).sum())]\n",
    "            # check that the sum of probabilities is not greater than 1\n",
    "            pr = [p if p >= 0 else 0 for p in pr]\n",
    "            pr[-1] = 1 - sum(pr[:-1])\n",
    "\n",
    "            for i, mt in enumerate(list(el[1].finditer(err_txt))):\n",
    "                ind_max = np.random.multinomial(1, pr, size=1)\n",
    "                if ind_max[0][-1] == 1:\n",
    "                    continue\n",
    "                exch = el[2][ind_max.argmax()]\n",
    "                err_txt = err_txt[: mt.start()] + exch + err_txt[mt.end() :]\n",
    "\n",
    "        incorrect_text.append(err_txt)\n",
    "    return incorrect_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "894ca467-25bb-4b8a-aa9f-0e7956fa44d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with Pool(processes=10) as pool:\n",
    "    res = pool.map(\n",
    "        get_text_with_error,\n",
    "        tqdm(\n",
    "            [\n",
    "                [res_new_str[i : i + 100], error_bank]\n",
    "                for i in range(0, len(res_new_str), 100)\n",
    "            ],\n",
    "            total=len(res_new_str) // 100 + 1,\n",
    "        ),\n",
    "    )\n",
    "    print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ec3e98-fe22-48bc-90bd-8dde1f252154",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0]\n",
    "\n",
    "data_new = pd.DataFrame(\n",
    "    list(zip(res_new_str, sum(res, []))), columns=[\"target\", \"input\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e959743d-dc0a-45b4-bb3b-5675c0eb7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada6456-f3d9-4a65-9fff-674f403fdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new[\"msg_len\"] = data_new[\"target\"].apply(lambda x: len(x))\n",
    "data_new[\"msg_len\"] = data_new[\"input\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43242c5f-55be-4e8b-ac15-be9078ab1b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new[\"msg_len\"].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a4e8dc-4b6d-4a33-abf4-ec0e282b9460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize everything and save to new columns. calculate the length of the input_ids array\n",
    "data_new[\"trg_target_token_len\"] = data_new[\"target\"].apply(\n",
    "    lambda x: len(roberta_tokenizer(x)[\"input_ids\"])\n",
    ")\n",
    "data_new[\"trg_input_token_len\"] = data_new[\"input\"].apply(\n",
    "    lambda x: len(roberta_tokenizer(x)[\"input_ids\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adb8e58-2e23-42cb-992a-865997cc0d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only save strings shorter than 500 characters\n",
    "data_new_len_500 = data_new[\n",
    "    (data_new[\"trg_target_token_len\"] > 500) | (data_new[\"trg_input_token_len\"] > 500)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb223261-3940-42d3-9c21-063a6ebcd7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new = data_new[\n",
    "    (data_new[\"trg_target_token_len\"] <= 500) & (data_new[\"trg_input_token_len\"] <= 500)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363c7ac5-e2cf-4934-a2d8-e3b68dc5fcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete consecutive punctuation marks\n",
    "data_new = data_new[\n",
    "    data_new[\"input\"].apply(lambda x: re.search(r\"[.:!]{3,}\", x) is None)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82495d42-be36-4578-9e30-da8262b2af11",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a9099c-771a-4b0b-b88f-48d7788dfc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# save everything to pickle\n",
    "with open(\"tokenized_data.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data_new, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
